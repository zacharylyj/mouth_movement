{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\zachary\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Could not understand audio\n",
      "T EH S T IH NG T EH S T\n",
      "------------------------------\n",
      "testing test ->\n",
      "['B', 'C', 'B', 'B', 'C', 'B', 'B', 'C', 'B', 'B']\n",
      "------------------------------\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "OOV\n",
      "------------------------------\n",
      "1112 ->\n",
      "['X']\n",
      "------------------------------\n",
      "Could not understand audio\n",
      "T EH S T IH NG\n",
      "------------------------------\n",
      "testing ->\n",
      "['B', 'C', 'B', 'B', 'C', 'B']\n",
      "------------------------------\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [27], line 105\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [27], line 93\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m         audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphrase_time_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Listen for 5 seconds\u001b[39;00m\n\u001b[0;32m     94\u001b[0m         text \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecognize_google(audio)\n\u001b[0;32m     95\u001b[0m         phonetic \u001b[38;5;241m=\u001b[39m text_to_phonetic(text)\n",
      "File \u001b[1;32mc:\\Users\\zachary\\anaconda3\\envs\\azureaistudio\\lib\\site-packages\\speech_recognition\\__init__.py:523\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m-\u001b[39m phrase_start_time \u001b[38;5;241m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    525\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\zachary\\anaconda3\\envs\\azureaistudio\\lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zachary\\anaconda3\\envs\\azureaistudio\\lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "mouth_shapes = {\n",
    "    'AA': 'Open mouth, tongue low',\n",
    "    'AE': 'Open mouth, tongue forward low',\n",
    "    'AH': 'Open mouth slightly, central tongue',\n",
    "    'AO': 'Rounded lips, tongue back',\n",
    "    'AW': 'Rounded lips, moving from open to closed',\n",
    "    'AY': 'Mouth wide open to slight close',\n",
    "    'B': 'Closed lips',\n",
    "    'CH': 'Teeth close, air burst',\n",
    "    'D': 'Tongue touches alveolar ridge',\n",
    "    'DH': 'Teeth close, tongue between',\n",
    "    'EH': 'Mouth open, tongue forward',\n",
    "    'ER': 'Rounded lips, tongue curled',\n",
    "    'EY': 'Mouth open, moving to close',\n",
    "    'F': 'Lower lip to upper teeth',\n",
    "    'G': 'Back of tongue against soft palate',\n",
    "    'HH': 'Open mouth, minimal tongue movement',\n",
    "    'IH': 'Slightly open mouth, tongue near front upper teeth',\n",
    "    'IY': 'Mouth slightly open, tongue high and forward',\n",
    "    'JH': 'Teeth close, tongue pushed against front teeth',\n",
    "    'K': 'Back of tongue against soft palate',\n",
    "    'L': 'Tip of tongue behind upper front teeth',\n",
    "    'M': 'Closed lips, nasal',\n",
    "    'N': 'Tongue touches alveolar ridge, nasal',\n",
    "    'NG': 'Back of tongue against soft palate, nasal',\n",
    "    'OW': 'Round lips moving from closed to slightly open',\n",
    "    'OY': 'Rounded lips, moving from open to closed',\n",
    "    'P': 'Closed lips, burst of air',\n",
    "    'R': 'Rounded lips, tongue curled back',\n",
    "    'S': 'Teeth close, tongue behind lower teeth',\n",
    "    'SH': 'Teeth close, tongue curled backward',\n",
    "    'T': 'Tongue touches alveolar ridge, burst of air',\n",
    "    'TH': 'Tongue between teeth, air passing',\n",
    "    'UH': 'Lips rounded, tongue pulled back slightly',\n",
    "    'UW': 'Lips rounded, tongue high and back',\n",
    "    'V': 'Upper teeth on lower lip',\n",
    "    'W': 'Lips rounded, relaxed',\n",
    "    'Y': 'Lips spread, tongue high',\n",
    "    'Z': 'Teeth close, tongue vibrates',\n",
    "    'ZH': 'Teeth close, tongue retracted slightly'\n",
    "}\n",
    "\n",
    "# Ensure you have the necessary resources\n",
    "nltk.download('cmudict')\n",
    "pron_dict = cmudict.dict()\n",
    "\n",
    "# Initialize the speech recognizer and microphone\n",
    "recognizer = sr.Recognizer()\n",
    "mic = sr.Microphone()\n",
    "\n",
    "def remove_numbers(string):\n",
    "    numbers_to_remove = ['0', '1', '3']\n",
    "    cleaned_string = ''.join(char for char in string if char not in numbers_to_remove)\n",
    "    return cleaned_string\n",
    "\n",
    "def text_to_phonetic(text):\n",
    "    words = text.lower().split()\n",
    "    phonetic_string =  remove_numbers(' '.join(' '.join(pron_dict[word][0]) if word in pron_dict else 'OOV' for word in words))\n",
    "    print(phonetic_string)\n",
    "    mouth_list = [\n",
    "        [\"AA\", \"D\"], [\"AE\", \"C\"], [\"AH\", \"C\"], [\"AO\", \"E\"], [\"AW\", \"E\"],\n",
    "        [\"AY\", \"E\"], [\"B\", \"A\"], [\"CH\", \"B\"], [\"D\", \"B\"], [\"DH\", \"B\"],\n",
    "        [\"EH\", \"C\"], [\"ER\", \"E\"], [\"EY\", \"E\"], [\"F\", \"G\"], [\"G\", \"B\"],\n",
    "        [\"HH\", \"H\"], [\"IH\", \"C\"], [\"IY\", \"B\"], [\"JH\", \"B\"], [\"K\", \"B\"],\n",
    "        [\"L\", \"H\"], [\"M\", \"A\"], [\"N\", \"B\"], [\"NG\", \"B\"], [\"OW\", \"F\"],\n",
    "        [\"OY\", \"F\"], [\"P\", \"A\"], [\"R\", \"B\"], [\"S\", \"B\"], [\"SH\", \"B\"],\n",
    "        [\"T\", \"B\"], [\"TH\", \"B\"], [\"UH\", \"E\"], [\"UW\", \"F\"], [\"V\", \"G\"],\n",
    "        [\"W\", \"F\"], [\"Y\", \"B\"], [\"Z\", \"B\"], [\"ZH\", \"B\"], [\"OOV\", \"X\"]\n",
    "    ]\n",
    "    mouth_movements = []\n",
    "    for phoneme in phonetic_string.split():\n",
    "        found = False\n",
    "        for pair in mouth_list:\n",
    "            if phoneme == pair[0]:\n",
    "                mouth_movements.append(pair[1])\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            mouth_movements.append(\"M\")\n",
    "    return mouth_movements\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    with mic as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)  # Adjust for ambient noise once at the beginning\n",
    "        print(\"Listening...\")\n",
    "        while True:\n",
    "            try:\n",
    "                audio = recognizer.listen(source, timeout=0.1, phrase_time_limit=3.0)  # Listen for 5 seconds\n",
    "                text = recognizer.recognize_google(audio)\n",
    "                phonetic = text_to_phonetic(text)\n",
    "                print(f\"------------------------------\\n{text} ->\\n{phonetic}\\n------------------------------\")\n",
    "            except sr.WaitTimeoutError:\n",
    "                pass\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Could not understand audio\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\zachary\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Could not understand audio\n",
      "T EH S T IH NG\n",
      "------------------------------\n",
      "testing ->\n",
      "['B', 'C', 'B', 'B', 'C', 'B']\n",
      "------------------------------\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "M IH K T EH S T W AH N T UW M AY T T EH S T W AH N T UW\n",
      "------------------------------\n",
      "mic test one two might test one two ->\n",
      "['A', 'C', 'B', 'B', 'C', 'B', 'B', 'F', 'C', 'B', 'B', 'F', 'A', 'E', 'B', 'B', 'C', 'B', 'B', 'F', 'C', 'B', 'B', 'F']\n",
      "------------------------------\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "S L AY T L IY F AE S T ER\n",
      "------------------------------\n",
      "slightly faster ->\n",
      "['B', 'H', 'E', 'B', 'H', 'B', 'G', 'C', 'B', 'B', 'E']\n",
      "------------------------------\n",
      "Could not understand audio\n",
      "Could not understand audio\n",
      "Could not understand audio\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 124\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 124\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [1], line 109\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 109\u001b[0m         audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphrase_time_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m         text \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecognize_google(audio)\n\u001b[0;32m    111\u001b[0m         phonetic \u001b[38;5;241m=\u001b[39m text_to_phonetic(text)\n",
      "File \u001b[1;32mc:\\Users\\zachary\\anaconda3\\envs\\azureaistudio\\lib\\site-packages\\speech_recognition\\__init__.py:523\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m-\u001b[39m phrase_start_time \u001b[38;5;241m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    525\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\zachary\\anaconda3\\envs\\azureaistudio\\lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zachary\\anaconda3\\envs\\azureaistudio\\lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "import time\n",
    "import speech_recognition as sr\n",
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "\n",
    "# Ensure you have the necessary resources\n",
    "nltk.download(\"cmudict\")\n",
    "pron_dict = cmudict.dict()\n",
    "\n",
    "# Initialize the speech recognizer and microphone\n",
    "recognizer = sr.Recognizer()\n",
    "mic = sr.Microphone()\n",
    "\n",
    "def remove_numbers(string):\n",
    "    numbers_to_remove = [\"0\", \"1\", \"3\"]\n",
    "    cleaned_string = \"\".join(char for char in string if char not in numbers_to_remove)\n",
    "    return cleaned_string\n",
    "\n",
    "def text_to_phonetic(text):\n",
    "    words = text.lower().split()\n",
    "    phonetic_string = remove_numbers(\n",
    "        \" \".join(\n",
    "            \" \".join(pron_dict[word][0]) if word in pron_dict else \"OOV\"\n",
    "            for word in words\n",
    "        )\n",
    "    )\n",
    "    print(phonetic_string)\n",
    "    mouth_list = [\n",
    "        [\"AA\", \"D\"], [\"AE\", \"C\"], [\"AH\", \"C\"], [\"AO\", \"E\"], [\"AW\", \"E\"],\n",
    "        [\"AY\", \"E\"], [\"B\", \"A\"], [\"CH\", \"B\"], [\"D\", \"B\"], [\"DH\", \"B\"],\n",
    "        [\"EH\", \"C\"], [\"ER\", \"E\"], [\"EY\", \"E\"], [\"F\", \"G\"], [\"G\", \"B\"],\n",
    "        [\"HH\", \"H\"], [\"IH\", \"C\"], [\"IY\", \"B\"], [\"JH\", \"B\"], [\"K\", \"B\"],\n",
    "        [\"L\", \"H\"], [\"M\", \"A\"], [\"N\", \"B\"], [\"NG\", \"B\"], [\"OW\", \"F\"],\n",
    "        [\"OY\", \"F\"], [\"P\", \"A\"], [\"R\", \"B\"], [\"S\", \"B\"], [\"SH\", \"B\"],\n",
    "        [\"T\", \"B\"], [\"TH\", \"B\"], [\"UH\", \"E\"], [\"UW\", \"F\"], [\"V\", \"G\"],\n",
    "        [\"W\", \"F\"], [\"Y\", \"B\"], [\"Z\", \"B\"], [\"ZH\", \"B\"], [\"OOV\", \"X\"],\n",
    "    ]\n",
    "    mouth_movements = []\n",
    "    for phoneme in phonetic_string.split():\n",
    "        found = False\n",
    "        for pair in mouth_list:\n",
    "            if phoneme == pair[0]:\n",
    "                mouth_movements.append(pair[1])\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            mouth_movements.append(\"M\")\n",
    "    return mouth_movements\n",
    "\n",
    "# Set up the display window\n",
    "root = tk.Tk()\n",
    "\n",
    "# Define paths to your images\n",
    "image_paths = {\n",
    "    \"A\": \"mouths/group2/lisa-A.png\",\n",
    "    \"B\": \"mouths/group2/lisa-B.png\",\n",
    "    \"C\": \"mouths/group2/lisa-C.png\",\n",
    "    \"D\": \"mouths/group2/lisa-D.png\",\n",
    "    \"E\": \"mouths/group2/lisa-E.png\",\n",
    "    \"F\": \"mouths/group2/lisa-F.png\",\n",
    "    \"G\": \"mouths/group2/lisa-G.png\",\n",
    "    \"H\": \"mouths/group2/lisa-H.png\",\n",
    "    \"X\": \"mouths/group2/lisa-X.png\",\n",
    "}\n",
    "\n",
    "# Load images and prepare for display after root is initialized\n",
    "images = {shape: Image.open(path) for shape, path in image_paths.items()}\n",
    "tk_images = {shape: ImageTk.PhotoImage(image) for shape, image in images.items()}\n",
    "\n",
    "label = tk.Label(root)\n",
    "label.pack()\n",
    "\n",
    "def display_image(shape):\n",
    "    label.config(image=tk_images[shape])\n",
    "    root.update()\n",
    "    time.sleep(0.2)  # Display each shape for half a second\n",
    "\n",
    "def add_transition_shapes(phonetic):\n",
    "    # Define special transitions\n",
    "    transitions = {\n",
    "        (\"A\", \"D\"): [\"A\", \"C\", \"D\"],\n",
    "        (\"B\", \"D\"): [\"B\", \"C\", \"D\"],\n",
    "        (\"C\", \"F\"): [\"C\", \"E\", \"F\"],\n",
    "        (\"D\", \"F\"): [\"D\", \"E\", \"F\"],\n",
    "    }\n",
    "    result = []\n",
    "    i = 0\n",
    "    while i < len(phonetic) - 1:\n",
    "        current_shape = phonetic[i]\n",
    "        next_shape = phonetic[i + 1]\n",
    "        if (current_shape, next_shape) in transitions:\n",
    "            result.extend(transitions[(current_shape, next_shape)])\n",
    "            i += 1  # Skip the next shape because it's already included in the transition\n",
    "        else:\n",
    "            result.append(current_shape)\n",
    "        i += 1\n",
    "    if i == len(phonetic) - 1:\n",
    "        result.append(phonetic[-1])\n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    with mic as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        print(\"Listening...\")\n",
    "        while True:\n",
    "            try:\n",
    "                audio = recognizer.listen(source, timeout=0.1, phrase_time_limit=3.0)\n",
    "                text = recognizer.recognize_google(audio)\n",
    "                phonetic = text_to_phonetic(text)\n",
    "                print(f\"------------------------------\\n{text} ->\\n{phonetic}\\n------------------------------\")\n",
    "                enhanced_phonetic = add_transition_shapes(phonetic)\n",
    "                for shape in enhanced_phonetic:\n",
    "                    display_image(shape)\n",
    "            except sr.WaitTimeoutError:\n",
    "                pass\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Could not understand audio\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/DanielSWolf/rhubarb-lip-sync?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display:flex; flex-wrap:wrap;'><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0001.png' style='width:100%'><br><small>mouth0001.png</small></div><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0002.png' style='width:100%'><br><small>mouth0002.png</small></div><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0003.png' style='width:100%'><br><small>mouth0003.png</small></div><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0004.png' style='width:100%'><br><small>mouth0004.png</small></div><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0005.png' style='width:100%'><br><small>mouth0005.png</small></div><br><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0006.png' style='width:100%'><br><small>mouth0006.png</small></div><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0007.png' style='width:100%'><br><small>mouth0007.png</small></div><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0008.png' style='width:100%'><br><small>mouth0008.png</small></div><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0009.png' style='width:100%'><br><small>mouth0009.png</small></div><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0010.png' style='width:100%'><br><small>mouth0010.png</small></div><br><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0011.png' style='width:100%'><br><small>mouth0011.png</small></div><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0012.png' style='width:100%'><br><small>mouth0012.png</small></div><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0013.png' style='width:100%'><br><small>mouth0013.png</small></div><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0014.png' style='width:100%'><br><small>mouth0014.png</small></div><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0015.png' style='width:100%'><br><small>mouth0015.png</small></div><br><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0016.png' style='width:100%'><br><small>mouth0016.png</small></div><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0017.png' style='width:100%'><br><small>mouth0017.png</small></div><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0018.png' style='width:100%'><br><small>mouth0018.png</small></div><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0019.png' style='width:100%'><br><small>mouth0019.png</small></div><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0020.png' style='width:100%'><br><small>mouth0020.png</small></div><br><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0021.png' style='width:100%'><br><small>mouth0021.png</small></div><div style='flex: 25%; padding: 5px; text-align: center;'><img src='mouths\\mouth0022.png' style='width:100%'><br><small>mouth0022.png</small></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import os\n",
    "def display_images_in_grid(directory, images_per_row=4):\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "    # Filter out only image files\n",
    "    image_files = [file for file in files if file.endswith((\".png\", \".jpg\", \".jpeg\", \".gif\"))]\n",
    "    \n",
    "    # Generate HTML for displaying images in a grid\n",
    "    html_output = \"<div style='display:flex; flex-wrap:wrap;'>\"\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        image_path = os.path.join(directory, image_file)\n",
    "        html_output += \"<div style='flex: 25%; padding: 5px; text-align: center;'>\"\n",
    "        html_output += f\"<img src='{image_path}' style='width:100%'><br>\"\n",
    "        html_output += f\"<small>{image_file}</small>\"\n",
    "        html_output += \"</div>\"\n",
    "        if (i + 1) % images_per_row == 0:\n",
    "            html_output += \"<br>\"\n",
    "    html_output += \"</div>\"\n",
    "    \n",
    "    # Display HTML content\n",
    "    display(HTML(html_output))\n",
    "\n",
    "# Specify the directory containing the images\n",
    "image_directory = \"mouths\"\n",
    "\n",
    "# Call the function to display images in a grid\n",
    "display_images_in_grid(image_directory, images_per_row=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureaistudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
